{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62aa590",
   "metadata": {},
   "source": [
    "# 기본 지도 학습 알고리즘들\n",
    "\n",
    "## 4. 로지스틱 회귀 (Logistic Regression)\n",
    "\n",
    "### 01. 분류 문제\n",
    "\n",
    "회귀는 연속적인 값을 예측하는 걸 의미하고 분류는 정해진 몇 개의 값 중에서 예측하는 걸 의미한다. 이때 분류를 위해 각 결괏값에 숫자를 지정해준다. 예를 들어 스팸 이메일을 분류할 때는 일반 이메일에 0이라는 값을 부여하고 스팸 이메일에는 1이라는 값을 부여할 수 있다. 이때 분류 문제를 풀 때 선형 회귀를 잘 사용하지 않는데 예외적인 데이터 하나로 인해 모델이 민감하게 변하기 때문이다.\n",
    "\n",
    "### 03. 로지스틱 회귀\n",
    "\n",
    "선형 회귀는 분류에 있어 값에 대해 모델의 변화가 크기 때문에 분류를 할 때는 주로 로지스틱 회귀(Logistic Regression)를 사용한다. 로지스틱 회귀는 데이터에 가장 잘 맞는 시그모이드 함수를 찾는 방법을 의미한다. 이때 시그모이드 함수의 식은 아래와 같다.\n",
    "\n",
    "\n",
    "$$\n",
    "S(x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "시그모이드 함수는 무조건 0과 1 사이의 값을 반환한다. $x$가 음의 무한대로 발산하면 값은 0에 가까워지며 반대로 $x$가 양의 무한대로 발산하면 값은 1에 가까워진다. 이때 결과가 0과 1 사이라는 것은 이상치에 대한 영향을 적게 받기 때문에 분류에 적합하다는 걸 의미한다. 추가적으로 시그모이드 함수의 결괏값이 0과 1 사이의 연속적인 값이기 때문에 회귀라는 단어를 사용한다.\n",
    "\n",
    "### 05. 로지스틱 회귀 가설 함수\n",
    "\n",
    "로지스틱 회귀의 가설 함수는 아래와 같다.\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x) = \\frac{1}{1+e^{-g_{\\theta}(x)}}\n",
    "$$\n",
    "\n",
    "이때 $g_{\\theta}(x)$ 값은 곧 선형 회귀의 가설 함수로 $\\theta^{T}x$와 같기 때문에 로지스틱 회귀의 가설 함수를 다시 정의해보면 아래와 같다.\n",
    "\n",
    "$$\n",
    "h_{\\theta}(x) = \\frac{1}{1+e^{-\\theta^{T}x}}\n",
    "$$\n",
    "\n",
    "$g_{\\theta}(x)$ 함수는 일차 함수로 결괏값이 엄청 클 수도, 작을 수도 있다. 다시 말해 양의 무한대와 음의 무한대로 발산한다. 이때 시그모이드 함수를 사용하여 해당 결괏값을 0과 1 사이로 바꾼다.\n",
    "\n",
    "### 08. 결정 경계\n",
    "\n",
    "로지스틱 회귀 뿐만 아니라 분류를 하는 모든 문제에 있어 데이터를 분류하기 위해 사용하는 선을 결정 경계(Decision Boundary)라 한다.\n",
    "\n",
    "### 09. 로그 손실\n",
    "\n",
    "로지스틱 회귀의 손실 함수는 선형 회귀의 손실 함수인 평균 제곱 오차를 사용하지 않고 로그 손실(Log Loss, Cross Entropy)를 사용한다. 이를 식으로 표현하면 아래 이미지와 같다.\n",
    "\n",
    "![로그 손실](./Images/1.png)\n",
    "\n",
    "이때 $h_{\\theta}(x)$값은 예측값, $y$값는 실제값을 의미하고 로그 손실 함수는 예측값이 실제값과 얼마나 괴리가 있는지 알려준다. 이때 로지스틱 회귀는 분류이고 가능한 경우는 0과 1로 이진 분류이기 때문에 두 개의 상황이 존재한다.\n",
    "\n",
    "추가적으로 손실의 정도를 로그 함수로 결정하기 때문에 로그 손실이라 부른다.\n",
    "\n",
    "### 11. 로지스틱 회귀 손실 함수\n",
    "\n",
    "로지스틱 회귀에서 손실 함수는 아래 식과 같이 나타내는데 이는 위에서 알아본 로그 손실 식과 동일하다.\n",
    "\n",
    "$$\n",
    "loglos(h_{\\theta}(x), y) = -ylog(h_{\\theta}(x)) - (1-y)log(1-h_{\\theta}(x)))\n",
    "$$\n",
    "\n",
    "이제 이렇게 구한 식에 대해 평균을 구하는 일반화된 식은 아래와 같다.\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}[logloss(h_{\\theta}(x^{(i)}), y^{(i)})]\n",
    "$$\n",
    "\n",
    "로그 손실 함수를 통해 i번째 값에 대해 구하여 해당 결과를 모두 더해 평균을 내는 것이다. 다시 말해 모든 데이터의 로그 손실을 계산한 후 평균을 낸다. 이때 가설 함수는 $\\theta$값에 따라 모델의 성능이 달라지기 때문에 손실 함수 또한 입력값으로 $\\theta$값을 사용한다.\n",
    "\n",
    "이렇게 구하게 된 로그 손실 함수를 앞서 구한 식으로 치환하면 결과는 아래와 같다.\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}[-ylog(h_{\\theta}(x)) - (1-y)log(1-h_{\\theta}(x)))]\n",
    "$$\n",
    "\n",
    "### 13. 로지스틱 회귀 경사 하강법\n",
    "\n",
    "경사 하강법은 손실을 최소화하는 방법 중 하나로 로지스틱 회귀에서도 경사 하강법을 통해 손실을 최소화할 수 있다. 처음에 $\\theta$값을 0 또는 임의로 설정한 뒤 해당 $\\theta$값을 조율하면서 손실을 최소화하면 된다.\n",
    "\n",
    "모든 $\\theta$값에 대해 선형 회귀와 마찬가지로 편미분을 시행한 뒤 점점 그 값을 최소화하면 되는데 그 편미분 결과 자체는 선형 회귀의 것과 유사하다. 이때 가설 함수에만 차이가 존재하는데 선형 회귀 함수의 가설 함수는 일차 함수인데 로지스틱 회귀의 가설 함수는 시그모이드 함수이기 때문이다. 결과적으로 시그모이드 함수를 통해 모든 $\\theta$값을 업데이트하여 손실을 최소화하면 된다.\n",
    "\n",
    "### 16. 로지스틱 회귀 가정 함수 구현하기\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "\n",
    "def prediction(X, theta):\n",
    "    return sigmoid(X@theta)\n",
    "\n",
    "    \n",
    "hours_studied = np.array(\n",
    "    [0.2, 0.3, 0.7, 1, 1.3, 1.8, 2, 2.1, 2.2, 3, 4, 4.2, 4, 4.7, 5.0, 5.9]\n",
    ")\n",
    "gpa_rank = np.array(\n",
    "    [0.9, 0.95, 0.8, 0.82, 0.7, 0.6, 0.55, 0.67, 0.4, 0.3, 0.2, 0.2, 0.15, 0.18, 0.15, 0.05]\n",
    ")\n",
    "number_of_tries = np.array(\n",
    "    [1, 2, 2, 2, 4, 2, 2, 2, 3, 3, 3, 3, 2, 4, 1, 2]\n",
    ")\n",
    "\n",
    "\n",
    "X = np.array([\n",
    "    np.ones(16),\n",
    "    hours_studied,\n",
    "    gpa_rank,\n",
    "    number_of_tries\n",
    "]).T\n",
    "theta = [0.5, 0.3, -2, 0.2]  \n",
    "\n",
    "prediction(X, theta)\n",
    "```\n",
    "\n",
    "### 17. 로지스틱 회귀 경사 하강법 구현하기\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "\n",
    "def prediction(X, theta):\n",
    "    return sigmoid(X@theta)\n",
    "    \n",
    "\n",
    "def gradient_descent(X, theta, y, iterations, alpha):\n",
    "    m = len(X)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        error = prediction(X, theta) - y\n",
    "        theta = theta - alpha/m * (X.T@error)\n",
    "            \n",
    "    return theta\n",
    "    \n",
    "\n",
    "hours_studied = np.array(\n",
    "    [0.2, 0.3, 0.7, 1, 1.3, 1.8, 2, 2.1, 2.2, 3, 4, 4.2, 4, 4.7, 5.0, 5.9]\n",
    ")\n",
    "gpa_rank = np.array(\n",
    "    [0.9, 0.95, 0.8, 0.82, 0.7, 0.6, 0.55, 0.67, 0.4, 0.3, 0.2, 0.2, 0.15, 0.18, 0.15, 0.05]\n",
    ")\n",
    "number_of_tries = np.array(\n",
    "    [1, 2, 2, 2, 4, 2, 2, 2, 3, 3, 3, 3, 2, 4, 1, 2]\n",
    ")\n",
    "passed = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "\n",
    "X = np.array([\n",
    "    np.ones(16),\n",
    "    hours_studied,\n",
    "    gpa_rank,\n",
    "    number_of_tries\n",
    "]).T\n",
    "y = passed\n",
    "\n",
    "theta = [0, 0, 0, 0]\n",
    "theta = gradient_descent(X, theta, y, 300, 0.1)\n",
    "\n",
    "theta\n",
    "```\n",
    "\n",
    "### 18. 분류가 3개 이상일 때\n",
    "\n",
    "예를 들어 직장 메일, 친구 메일, 스팸 메일과 같이 세 개로 분류를 하고자 할 때 직장 메일과 기타 나머지 메일로 이진분류를 하는 가설 함수, 친구 메일과 기타 나머지 메일로 이진분류를 하는 가설 함수, 그리고 스팸 메일과 기타 나머지 메일로 이진분류를 하는 가설 함수를 각각 만든다. 그리고 하나의 데이터에 대해 각각의 가설 함수에 대한 결괏값을 구한 뒤 가장 정확도가 높은 가설 함수를 선택하게 되면 해당 메일로 분류가 된다.\n",
    "\n",
    "![세 개 이상의 분류](./Images/2.png)\n",
    "\n",
    "### 20. 로지스틱 회귀와 정규 방정식\n",
    "\n",
    "로지스틱 회귀의 손실 함수 또한 Convex 함수이기 때문에 경사 하강법을 사용하여 최적의 $\\theta$값을 구할 수 있는데 $\\theta$값이 $\\e$의 지수에 포함되어 있는 등 $\\J$값에 대한 편미분 원소들이 선형식이 아니기 때문에 일차식만으로 표현할 수 없다. 따라서 단순 행렬 연산만으로 최소 지점을 찾아낼 수 없다. 이 부분이 앞서 선형 회귀의 경사 하강법과 로지스틱 회귀의 경사 하강법 차이다.\n",
    "\n",
    "### 23. 로지스틱 회귀로 와인 종류 분류하기\n",
    "\n",
    "```Python\n",
    "# 23. 로지스틱 회귀로 와인 분류하기\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "wine_data = datasets.load_wine()\n",
    "\n",
    "X = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "y = pd.DataFrame(wine_data.target, columns=['Y/N'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "logistic_model = LogisticRegression(solver=\"saga\", max_iter=7500)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict = logistic_model.predict(X_test)\n",
    "\n",
    "score = logistic_model.score(X_test, y_test)\n",
    "y_test_predict, score\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d741151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26114999, 0.28699984, 0.37989357, 0.39174097, 0.57199613,\n",
       "       0.55971365, 0.59868766, 0.54735762, 0.72312181, 0.80218389,\n",
       "       0.86989153, 0.87653295, 0.85814894, 0.91293423, 0.86989153,\n",
       "       0.9289057 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16. 로지스틱 회귀 가정 함수 구현하기\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "\n",
    "def prediction(X, theta):\n",
    "    return sigmoid(X@theta)\n",
    "\n",
    "    \n",
    "hours_studied = np.array(\n",
    "    [0.2, 0.3, 0.7, 1, 1.3, 1.8, 2, 2.1, 2.2, 3, 4, 4.2, 4, 4.7, 5.0, 5.9]\n",
    ")\n",
    "gpa_rank = np.array(\n",
    "    [0.9, 0.95, 0.8, 0.82, 0.7, 0.6, 0.55, 0.67, 0.4, 0.3, 0.2, 0.2, 0.15, 0.18, 0.15, 0.05]\n",
    ")\n",
    "number_of_tries = np.array(\n",
    "    [1, 2, 2, 2, 4, 2, 2, 2, 3, 3, 3, 3, 2, 4, 1, 2]\n",
    ")\n",
    "\n",
    "\n",
    "X = np.array([\n",
    "    np.ones(16),\n",
    "    hours_studied,\n",
    "    gpa_rank,\n",
    "    number_of_tries\n",
    "]).T\n",
    "theta = [0.5, 0.3, -2, 0.2]  \n",
    "\n",
    "prediction(X, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1605644d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.35280508,  1.61640725, -1.83666046, -0.60286277])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 17. 로지스틱 회귀 경사 하강법 구현하기\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "\n",
    "def prediction(X, theta):\n",
    "    return sigmoid(X@theta)\n",
    "    \n",
    "\n",
    "def gradient_descent(X, theta, y, iterations, alpha):\n",
    "    m = len(X)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        error = prediction(X, theta) - y\n",
    "        theta = theta - alpha/m * (X.T@error)\n",
    "            \n",
    "    return theta\n",
    "    \n",
    "\n",
    "hours_studied = np.array(\n",
    "    [0.2, 0.3, 0.7, 1, 1.3, 1.8, 2, 2.1, 2.2, 3, 4, 4.2, 4, 4.7, 5.0, 5.9]\n",
    ")\n",
    "gpa_rank = np.array(\n",
    "    [0.9, 0.95, 0.8, 0.82, 0.7, 0.6, 0.55, 0.67, 0.4, 0.3, 0.2, 0.2, 0.15, 0.18, 0.15, 0.05]\n",
    ")\n",
    "number_of_tries = np.array(\n",
    "    [1, 2, 2, 2, 4, 2, 2, 2, 3, 3, 3, 3, 2, 4, 1, 2]\n",
    ")\n",
    "passed = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "\n",
    "X = np.array([\n",
    "    np.ones(16),\n",
    "    hours_studied,\n",
    "    gpa_rank,\n",
    "    number_of_tries\n",
    "]).T\n",
    "y = passed\n",
    "\n",
    "theta = [0, 0, 0, 0]\n",
    "theta = gradient_descent(X, theta, y, 300, 0.1)\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c436c4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(iris_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99fdafc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "X = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b586e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "..     ...\n",
       "145      2\n",
       "146      2\n",
       "147      2\n",
       "148      2\n",
       "149      2\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.DataFrame(iris_data.target, columns=[\"class\"])\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68663c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 2, 1, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\n",
    "Y_train = Y_train.values.ravel()\n",
    "\n",
    "# solver 매개변수로 모델 최적화 때 사용하는 알고리즘과 max_iter 매개변수로 최대 반복 횟수를 전달한다.\n",
    "# 이때 max_iter 매개변수에 전달하는 값만큼 전부 반복하지는 않고 그 전에도 충분히 최적화가 되었다고 판단하면 최적화를 중단한다.\n",
    "# 추가적으로 학습률 알파값의 경우 자동으로 최적화가 되어 있다.\n",
    "model = LogisticRegression(solver=\"saga\", max_iter=2000)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predict = model.predict(X_test)\n",
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d485edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 성능 평가\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61c4d57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 0, 2, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 2, 0, 1, 1, 0, 0, 2, 2]),\n",
       " 0.75)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 23. 로지스틱 회귀로 와인 분류하기\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "wine_data = datasets.load_wine()\n",
    "\n",
    "X = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "y = pd.DataFrame(wine_data.target, columns=['Y/N'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "logistic_model = LogisticRegression(solver=\"saga\", max_iter=7500)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict = logistic_model.predict(X_test)\n",
    "\n",
    "score = logistic_model.score(X_test, y_test)\n",
    "y_test_predict, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588db56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
